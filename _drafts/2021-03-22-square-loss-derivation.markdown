---
title: "Machine Learning Loss Math Cheat Sheet"
date: 2021-03-21 12:00:00 -0700
comments: true
author: "Will High"
categories: 
  - machine learning
tags:
  - loss function
excerpt: Derive losses from likelihood plus optional regularization priors.
---

{% include toc %}

# tl;dr 

Cheat sheet for deriving loss functions from a data generating model likelihood
and optional priors. This post is different from other cheat sheets because it
includes more model types than I have typically seen in one place,
including survival and quantile models. 

# Bayes theorem

Bayes' theorem tells us that the posterior probability of a hypothesis $h$ given data $D$ is

\begin{equation}
P(H|D) = \frac{P(H) P(D|H)}{P(D)},
\end{equation}

where

* $P(H \vert D)$ is the **posterior** probability of the (variable) hypothesis given the (fixed) observed data
* $P(H)$ is the **prior** probability of the hypothesis
* $P(D \vert H)$ is the probability that the observed data was generated by $H$, aka the **likelihood**
* $P(D)$ is the marginal likelihood, usually discarded because it's not a function of $H$.

In supervised machine learning,
models are hypotheses
and data are
$y_i | \mathbf{x}_i$ label-feature vector tuples.

We're looking for the best model, which maximizes the posterior probability. 

\begin{equation}
f_{\textrm{best}} = \textrm{argmax}_f p(h) p({y | \mathbf{x}} | h)
\end{equation}

# Gradient descent and gradient boosting

An objective function is derived from a likelihood function, and more generally from a posterior probability
function, by taking the log, which turns products into sums. 
Probability maximization is turned into function minimization by multiple by -1 and ignoring any other additive and
multiplicative constants. 
You end up with functions that can be written in the form of a risk function

$$
L = \frac{1}{N}\sum_i^{N} \ell_i
$$

i.e., the mean of a loss function $\ell(\mathbf{x}_i)$. 

## In linear regression, gradient descent happens in coefficient space

For linear models like least-squares and logistic regression, 

$$
\ell = \ell(f(\beta; \mathbf{x}_i))
$$

where 

$$
f(\beta; \mathbf{x}_i) = \mathbf{x}_i^T \mathbf{\beta},
$$

This forumaltion supports an offset or y-intercept term by defining $x_0 = 1$. 
The linear function $f$ is mapped to parameters of the likelihood model via a link funtion. 
For example, the link for ordinary least squares is the trivial identity function, and 
for logistic regression it's the probit, which is the inverse of the sigmoid. 

Gradient descent minimazation methods make use of the first partial derivative or "subgradient".

$$\begin{eqnarray}
\ell^{\prime} & = & \frac{\partial \ell}{\partial \mathbf{\beta}} \\
 & = & \mathbf{x}_i \frac{\partial \ell}{\partial f} 
\end{eqnarray}$$

Sometimes gradient descent the second partial derivative or *Hessian*.

$$\begin{eqnarray}
\ell^{\prime\prime} & = & \frac{\partial^2 \ell}{\partial \mathbf{\beta}^2} \\
 & = & \mathbf{x}_i^2 \frac{\partial^2 \ell}{\partial f^2} 
\end{eqnarray}$$

## In gradient boosting, gradient descent happens in function space

In gradient boosting, 

$$
\ell = \ell(f)
$$

where 

optimization is done over the set of different functions $f$ in functional space
rather than over parameters of a single linear function. In this case the gradient is just

$$\begin{eqnarray}
\ell^{\prime} & = & \frac{\partial \ell}{\partial f}
\end{eqnarray}$$

and the Hessian is

$$\begin{eqnarray}
\ell^{\prime\prime} & = & \frac{\partial^2 \ell}{\partial f^2}.
\end{eqnarray}$$

All derivatives below will be computed with respect to $f$.
If you are using them in a gradient boosting context, this is all you need.
If you are using them in a linear model context, 
you need to multiply the gradient and Hessian by $\mathbf{x}_i$ and $\mathbf{x}_i$, respectively.

# Likelihood, loss, gradient, hessian

The loss is the negative log-likelihood for a single data point.

## Square loss

Used in continous variable regression problems. 

Likelihood function, called Gaussian or normal:

$$\begin{equation}
\prod_{i=1}^N\frac{1}{\sigma\sqrt{2\pi}}\exp{-\frac{(y_i - f(\mathbf{x}_i))^2}{2\sigma^2}}
\end{equation}$$

Loss function:

$$\begin{equation}
\ell = (y_i - f(\mathbf{x}_i))^2
\end{equation}$$

Gradient:

$$\begin{equation}
\frac{\partial \ell}{\partial f} = 2(f(\mathbf{x}_i) - y_i)
\end{equation}$$

Hessian:

$$\begin{equation}
\frac{\partial^2 \ell}{\partial f^2} = 2
\end{equation}$$


## Log loss

Used in binary classifiction problems. 

Likelihood function:

Bernoulli

\begin{equation}
\prod_{i=1}^N p(\mathbf{x}_i)^{y_i} (1 - p(\mathbf{x}_i))^{1 - {y_i}}
\end{equation}

The model in this case is a function 
with support $h \in \\{-\infty, \infty\\}$ that maps to the Bernoulli
probability parameter $p$ via the log-odds or "logit" link function.

\begin{equation} 
f(\mathbf{x}_i) = \log{\frac{p(\mathbf{x}_i)}{1 - p(\mathbf{x}_i)}}
\end{equation}

This formulation maps the boundless hypotheses 
onto probabilities $p \in \\{0, 1\\}$ by just solving for $p$:

\begin{equation} 
p(\mathbf{x}_i) = \frac{1}{1 + \exp{(-f(\mathbf{x}_i))}}
\end{equation}


Loss function

For labels following the binary indicator convention $y \in \\{0, 1\\}$, 
all of the following are equivalent. The easiest way to prove
they are equivalent is to plug in $y = 0$ and $y = 1$ and rearrange.

$$\begin{eqnarray}
\ell & = & -y_i\log{p(\mathbf{x}_i)} - (1 - y_i)\log{(1 - p(\mathbf{x}_i))} \\
  & = & y_i \log{(1 + \exp{(-f(\mathbf{x}_i))})} + (1 - y_i) \log{(1 + \exp{(f(\mathbf{x}_i))})}  \\
  & = & - y_i f(\mathbf{x}_i) + \log{(1 + \exp{(f(\mathbf{x}_i))})}
\end{eqnarray}$$

The first form is useful if you want to use different link functions. 

For labels following the transformed convention $z = 2y-1 \in \\{-1, 1\\}$:

$$\begin{equation}
\ell = \log{(1 + exp{(-g f(\mathbf{x}_i))})}
\end{equation}$$

Gradient

$$\begin{eqnarray}
\frac{\partial \ell}{\partial f} & = & p(\mathbf{x}_i) - y_i 
\end{eqnarray}$$

Hessian

$$\begin{eqnarray}
\frac{\partial^2 \ell}{\partial f^2} & = & p(\mathbf{x}_i)(1 - p(\mathbf{x}_i)) 
\end{eqnarray}$$



## Cox proportional hazards survival

Likelihood function: Cox partial likelihood

Loss function 

Gradient

Hessian

## Weibull survival


## More survival


## Quantile regression

Likelihood function

Loss function, sometimes called the pinball loss.

$$\begin{eqnarray}
\ell & = & (y_i - f(\mathbf{x}_i)) ( \tau  - \mathbb{1}_{y_i < f(\mathbf{x}_i)} ) \\
& = & \sum_{y_i \geq f(\mathbf{x}_i)}\tau (y_i - f(\mathbf{x}_i)) - \sum_{y_i < f(\mathbf{x}_i)}(1 - \tau) (y_i - f(\mathbf{x}_i))
\end{eqnarray}$$


Gradient

$$\begin{eqnarray}
\frac{\partial \ell}{\partial f} & = & - ( \tau  - \mathbb{1}_{y_i < f(\mathbf{x}_i)} ) \\
  & = & - \sum_{y_i \geq f(\mathbf{x}_i)}\tau + \sum_{y_i < f(\mathbf{x}_i)}(1 - \tau)
\end{eqnarray}$$

Hessian

$$\begin{eqnarray}
\frac{\partial^2 \ell}{\partial f^2} & = & 0
\end{eqnarray}$$

## Mean absolute deviation

Mean absolute deviation is quantile regression at $\tau=0.5$.

## Hinge



## Huber


## Poisson


## Kullback-Leibler







# Regularizing priors


# Further reading


* [R GBM vignette, Section 4 "Available Distributions"](https://cran.r-project.org/web/packages/gbm/vignettes/gbm.pdf)
* [ML Cheat Sheet, Section "Loss Functions"](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)
* [Supervised Learning cheatsheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning)
* [Stochastic Gradient Descent Tricks](https://www.microsoft.com/en-us/research/wp-content/uploads/2012/01/tricks-2012.pdf)

